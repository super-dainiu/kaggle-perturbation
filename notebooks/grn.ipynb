{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "\n",
    "os.chdir('/home/yz979/code/kaggle-perturbation/')\n",
    "\n",
    "adata_path = 'data/adata_train.h5ad'\n",
    "de_path = 'data/de_train.h5ad'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Union\n",
    "\n",
    "import anndata\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import scanpy as sc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataverse_download(url, save_path):\n",
    "    \"\"\"\n",
    "    Dataverse download helper with progress bar\n",
    "\n",
    "    Args:\n",
    "        url (str): the url of the dataset\n",
    "        path (str): the path to save the dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    if os.path.exists(save_path):\n",
    "        print('Found local copy...')\n",
    "    else:\n",
    "        print(\"Downloading...\")\n",
    "        response = requests.get(url, stream=True)\n",
    "        total_size_in_bytes= int(response.headers.get('content-length', 0))\n",
    "        block_size = 1024\n",
    "        progress_bar = tqdm(total=total_size_in_bytes, unit='iB', unit_scale=True)\n",
    "        with open(save_path, 'wb') as file:\n",
    "            for data in response.iter_content(block_size):\n",
    "                progress_bar.update(len(data))\n",
    "                file.write(data)\n",
    "        progress_bar.close()\n",
    "\n",
    "def get_go_auto(gene_list, data_path):\n",
    "    \"\"\"\n",
    "    Get gene ontology data\n",
    "\n",
    "    Args:\n",
    "        gene_list (list): list of gene names\n",
    "        data_path (str): path to data\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: gene ontology data\n",
    "    \"\"\"\n",
    "    \n",
    "    data_path.mkdir(parents=True, exist_ok=True)\n",
    "    go_path = os.path.join(data_path, 'go.csv')\n",
    "    \n",
    "    if os.path.exists(go_path):\n",
    "        return pd.read_csv(go_path)\n",
    "    else:\n",
    "        if not os.path.exists(os.path.join(data_path, 'gene2go.pkl')):\n",
    "            # download gene2go.pkl\n",
    "            server_path = 'https://dataverse.harvard.edu/api/access/datafile/6153417' \n",
    "            dataverse_download(server_path, os.path.join(data_path, 'gene2go.pkl'))\n",
    "            \n",
    "        with open(os.path.join(data_path, 'gene2go.pkl'), 'rb') as f:\n",
    "            gene2go = pickle.load(f)\n",
    "\n",
    "        # Filter gene2go mapping to current genes\n",
    "        gene2go = {i: list(gene2go[i]) for i in gene_list if i in gene2go}\n",
    "        edge_list = []\n",
    "        for g1 in tqdm(gene2go.keys()):\n",
    "            for g2 in gene2go.keys():\n",
    "                edge_list.append((g1, g2, len(np.intersect1d(gene2go[g1], gene2go[g2]))/\n",
    "                                   len(np.union1d(gene2go[g1], gene2go[g2]))))\n",
    "\n",
    "        # Filter edges\n",
    "        edge_list = [i for i in edge_list if i[2] > 0.1]\n",
    "        edge_df = pd.DataFrame(edge_list).rename(columns={0: 'gene1', \n",
    "                                                          1: 'gene2',\n",
    "                                                          2: 'score'})\n",
    "\n",
    "        edge_df = edge_df.rename(columns={'gene1': 'source',\n",
    "                                          'gene2': 'target',\n",
    "                                          'score': 'importance'})\n",
    "        edge_df.to_csv(go_path, index=False)\n",
    "        \n",
    "        return edge_df\n",
    "\n",
    "\n",
    "def get_coexpress_auto(adata, threshold=0.5):\n",
    "    df = adata.to_df()\n",
    "    gene_names = df.columns\n",
    "    \n",
    "    # Calculate correlation matrix\n",
    "    cor_matrix = df.corr(method='pearson')\n",
    "\n",
    "    # Filter edges\n",
    "    edges = []\n",
    "    for i in range(len(cor_matrix)):\n",
    "        for j in range(i+1, len(cor_matrix)):\n",
    "            if abs(cor_matrix.iloc[i, j]) > threshold:\n",
    "                edges.append((gene_names[i], gene_names[j], cor_matrix.iloc[i, j]))\n",
    "    \n",
    "    edge_df = pd.DataFrame(edges, columns=['source', 'target', 'importance'])\n",
    "    edge_df.to_csv('data/coexpression.csv', index=False)\n",
    "    return edge_df\n",
    "\n",
    "def gene_sim_network(\n",
    "    gene_list: List[str],\n",
    "    node_map: Dict[str, int],\n",
    "    network_type: str,\n",
    "    adata: anndata.AnnData = None,\n",
    "    data_path: str = './data',\n",
    "    threshold: float = 0.5,\n",
    ") -> \"GeneSimNetwork\":\n",
    "    \"\"\"\n",
    "    Get gene similarity network\n",
    "\n",
    "    Args:\n",
    "        gene_list (list): list of gene names\n",
    "        node_map (dict): dictionary mapping gene names to node indices\n",
    "        network_type (str): type of network to use\n",
    "        data_path (str): path to data\n",
    "        threshold (float): threshold for coexpression network\n",
    "\n",
    "    Returns:\n",
    "        GeneSimNetwork: gene similarity network\n",
    "\n",
    "    Usage:\n",
    "        >>> gene_list = ['ENSG00000139618', 'ENSG00000141510', 'ENSG00000141510']\n",
    "        >>> node_map = {'ENSG00000139618': 0, 'ENSG00000141510': 1}\n",
    "        >>> network = get_gene_sim_network(gene_list, node_map, 'go')\n",
    "    \"\"\"\n",
    "    data_path = Path(data_path)\n",
    "    \n",
    "    if network_type == 'go':\n",
    "        edge_list = get_go_auto(gene_list, data_path)\n",
    "    elif network_type == 'coexpression':\n",
    "        edge_list = get_coexpress_auto(adata, threshold)\n",
    "\n",
    "    network = GeneSimNetwork.from_edges(edge_list, gene_list, node_map)\n",
    "    return network\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class GeneSimNetwork():\n",
    "    G: nx.DiGraph\n",
    "    edge_index: torch.Tensor\n",
    "    edge_weight: torch.Tensor\n",
    "    \n",
    "    @classmethod\n",
    "    def from_edges(\n",
    "        cls,\n",
    "        edge_list: pd.DataFrame,\n",
    "        gene_list: List,\n",
    "        node_map: Dict[str, int],\n",
    "        ) -> \"GeneSimNetwork\":\n",
    "        \"\"\"\n",
    "        Generate gene similarity network from edge list\n",
    "\n",
    "        Args:\n",
    "            edge_list (pd.DataFrame): edge list of the network\n",
    "            gene_list (list): list of gene names\n",
    "            node_map (dict): dictionary mapping gene names to node indices\n",
    "\n",
    "        Returns:\n",
    "            GeneSimNetwork: gene similarity network\n",
    "        \"\"\"\n",
    "        G = nx.from_pandas_edgelist(edge_list, source='source',\n",
    "                                    target='target', edge_attr=['importance'],\n",
    "                                    create_using=nx.DiGraph())\n",
    "        for n in gene_list:\n",
    "            if n not in G.nodes():\n",
    "                G.add_node(n)\n",
    "\n",
    "        to_remove = []\n",
    "        for n in G.nodes():\n",
    "            if n not in gene_list:\n",
    "                to_remove.append(n)\n",
    "        \n",
    "        for n in to_remove:\n",
    "            G.remove_node(n)\n",
    "\n",
    "        edge_index_ = [(node_map[e[0]], node_map[e[1]]) for e in G.edges]\n",
    "\n",
    "        edge_index = torch.tensor(edge_index_, dtype=torch.long).T\n",
    "        \n",
    "        edge_attr = nx.get_edge_attributes(G, 'importance') \n",
    "        importance = np.array([edge_attr[e] for e in G.edges])\n",
    "        edge_weight = torch.Tensor(importance)\n",
    "        \n",
    "        return cls(G, edge_index, edge_weight)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.G.nodes)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.G.nodes[idx]\n",
    "    \n",
    "    def __contains__(self, item):\n",
    "        return item in self.G.nodes\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return iter(self.G.nodes)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.G.__repr__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = anndata.read_h5ad(adata_path)\n",
    "de_train = anndata.read_h5ad(de_path)\n",
    "node_map = {i: j for i, j in zip(de_train.var.index, range(len(de_train.var)))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "coexpress_network = gene_sim_network(adata.var.index, node_map, 'coexpression', adata=adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12680/12680 [1:23:17<00:00,  2.54it/s]\n"
     ]
    }
   ],
   "source": [
    "edge_df = get_go_auto(de_train.var.index, Path('data') / 'grn')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
